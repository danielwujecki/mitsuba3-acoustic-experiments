{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acoustic Integration - Ceiling Sail Orientation\n",
    "\n",
    "http://localhost:8888/?token=sloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"mi\" not in vars():\n",
    "    from tqdm import trange\n",
    "\n",
    "    # import torch\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import drjit as dr\n",
    "    import mitsuba as mi\n",
    "\n",
    "    from libs import utils\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    mi.set_variant('cuda_ad_acoustic')\n",
    "    mi.set_log_level(mi.LogLevel.Warn)\n",
    "\n",
    "    sess_seed   = 0 # np.random.randint(0, 2**30)\n",
    "    sess_seed_g = 1 # np.random.randint(0, 2**30)\n",
    "    print(f\"session seeds are: sess_seed={sess_seed}; sess_seed_g={sess_seed_g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_poses = np.array([[4., 2., 5.]])\n",
    "# mic_poses = np.array([[11., 3., 5.]])\n",
    "\n",
    "sail_poses_dict = {}\n",
    "sail_size    = np.array([  4.,  2., 4.]) / 2.\n",
    "sail_poses   = np.array([[ 4., 16., 2.5],\n",
    "                         [ 4., 16., 7.5],\n",
    "                         [10., 16., 2.5],\n",
    "                         [10., 16., 7.5]])\n",
    "# sail_poses   = np.array([[ 11., 16., 5]])\n",
    "\n",
    "config = {\n",
    "    \"box_dim\":     [22., 18., 10.],\n",
    "    \"mic_pos\":     mic_poses[0],\n",
    "    \"speaker_pos\": [18.,  2., 5.],\n",
    "    # \"speaker_pos\": [11., 1.5, 5.],\n",
    "    \"speaker_radius\": 1.0,\n",
    "\n",
    "    \"absorption\": 0.5,\n",
    "    \"scattering\": 0.5,\n",
    "\n",
    "    \"wav_bins\":  mic_poses.shape[0],\n",
    "    \"time_bins\": 10,\n",
    "    \"max_time\":  0.2,\n",
    "\n",
    "    \"integrator\": \"prb_reparam_acoustic\",\n",
    "    \"max_depth\": 2,\n",
    "    \"spp\": 2**22,\n",
    "}\n",
    "\n",
    "tf      = mi.ScalarTransform4f\n",
    "box_dim = np.array(config['box_dim']) / 2.\n",
    "time    = np.linspace(0., config[\"max_time\"], config[\"time_bins\"], endpoint=False)\n",
    "\n",
    "# config[\"max_depth\"] = utils.estimate_max_depth(config[\"box_dim\"], config[\"max_time\"], 1.5)\n",
    "print(f\"max_depth = {config['max_depth']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict = utils.shoebox_scene(**config)\n",
    "\n",
    "scene_dict[\"integrator\"][\"skip_direct\"] = True\n",
    "# scene_dict[\"sensor\"][\"film\"][\"rfilter\"] = {\n",
    "#     \"type\": \"gaussian\",\n",
    "#     \"stddev\": 0.1 * 343. * config[\"max_time\"] / config[\"time_bins\"],\n",
    "# }\n",
    "\n",
    "del scene_dict[\"sensor\"][\"microphoneA\"]\n",
    "for i, m in enumerate(mic_poses):\n",
    "    scene_dict[\"sensor\"][f\"microphone_{i}\"] = {\n",
    "        \"type\": \"microphone\",\n",
    "        \"cos_cutoff\": 0.0,\n",
    "        \"to_world\": tf.look_at(\n",
    "            origin=(m - box_dim),\n",
    "            target=(np.mean(sail_poses, axis=0) - box_dim),\n",
    "            up=[0, 0, 1]\n",
    "        ),\n",
    "        # \"to_world\": tf.translate(m - box_dim),\n",
    "    }\n",
    "\n",
    "sail_vertex_base = mi.Transform4f.scale(sail_size).rotate([1., 0., 0.], angle=90.) @ mi.Point3f(\n",
    "    [-1., -1.,  1.,  1.],\n",
    "    [-1.,  1., -1.,  1.],\n",
    "    [ 0.,  0.,  0.,  0.]\n",
    ")\n",
    "\n",
    "for i, s in enumerate(sail_poses):\n",
    "    sail_poses_dict[f\"sail_{i}.vertex_positions\"] = mi.Point3f(s - box_dim)\n",
    "    scene_dict[f\"sail_{i}\"] = {\n",
    "        \"type\": \"ply\",\n",
    "        \"filename\": \"/home/daniel/Studium/masterarbeit/data/scenes/meshes/rectangle.ply\",\n",
    "        \"bsdf\": {\n",
    "            \"type\": \"acousticbsdf\",\n",
    "            \"scattering\": { \"type\": \"spectrum\", \"value\": 0.1 },\n",
    "            \"absorption\": { \"type\": \"spectrum\", \"value\": 0.2 },\n",
    "        },\n",
    "        \"to_world\": tf.translate(s - box_dim).scale(sail_size).rotate([1., 0., 0.], angle=90.),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mi.ad.Adam(lr=0.0025)\n",
    "# opt[\"sail_0.vertex_positions\"] = mi.Point2f(0.0, 0.0)\n",
    "# opt[\"sail_1.vertex_positions\"] = mi.Point2f( 0.10, 0.7)\n",
    "opt[\"sail_0.vertex_positions\"] = mi.Point2f(-0.10, 0.2)\n",
    "opt[\"sail_1.vertex_positions\"] = mi.Point2f( 0.10, 0.2)\n",
    "opt[\"sail_2.vertex_positions\"] = mi.Point2f(-0.15, 0.5)\n",
    "opt[\"sail_3.vertex_positions\"] = mi.Point2f( 0.15, 0.5)\n",
    "\n",
    "# V = np.load(\"../data/ceiling-sail/ceiling-sail-single-mic-01.npy\")\n",
    "# for i, key in enumerate(sail_poses_dict):\n",
    "    # opt[key] = mi.Point2f(V[0, -1, i])\n",
    "    # print(opt[key])\n",
    "    # opt[key] = mi.Point2f(0.0, 0.0)\n",
    "    # opt[key] = mi.Point2f(*(np.random.rand(2) * 2. - 1.))\n",
    "\n",
    "def apply_transform(params_to_update, optim):\n",
    "    for key in sail_poses_dict:\n",
    "        optim[key] = dr.clamp(optim[key], -2., 2.)\n",
    "        transf = mi.Transform4f.translate(sail_poses_dict[key]) \\\n",
    "                               .rotate(axis=[1., 0., 0.], angle=(optim[key].x * 30.)) \\\n",
    "                               .rotate(axis=[0., 0., 1.], angle=(optim[key].y * 30.))\n",
    "        params_to_update[key] = dr.ravel(transf @ sail_vertex_base)\n",
    "    params_to_update.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(hist, ref=None):\n",
    "    assert ref is None\n",
    "    return dr.sum(hist[:, :, 0])\n",
    "    # return dr.mean(dr.sqr(hist[:, :, 0]))\n",
    "    # return dr.rcp(dr.mean(hist[:, :, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = False\n",
    "out_view = False\n",
    "if visualize and out_view:\n",
    "    scene_dict_vis = utils.shoebox_scene_visual(resf=6, **config)\n",
    "\n",
    "    scene_dict_vis[\"sensor\"][\"film\"][\"width\"]  = 200 * 4\n",
    "    scene_dict_vis[\"sensor\"][\"film\"][\"height\"] = 100 * 3\n",
    "    scene_dict_vis[\"sensor\"][\"cameraA\"][\"to_world\"] = tf.look_at(\n",
    "        origin=np.array([-44., -1.8, 40.]),\n",
    "        # origin=np.array([-32., 22, 40.]),\n",
    "        target=np.zeros(3),\n",
    "        up=[0, 1, 0]\n",
    "    )\n",
    "    scene_dict_vis[\"sensor\"][\"cameraB\"] = {\n",
    "        \"type\": \"perspective\",\n",
    "        \"to_world\": tf.look_at(\n",
    "            origin=np.array([0., -1.8, 55.]),\n",
    "            target=np.zeros(3),\n",
    "            up=[0, 1, 0]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    del scene_dict_vis[\"microphoneA\"]\n",
    "    for i, m in enumerate(mic_poses):\n",
    "        scene_dict_vis[f\"microphone_{i}\"] = {\n",
    "            \"type\": \"sphere\",\n",
    "            \"radius\": .25,\n",
    "            \"to_world\": tf.translate(m - box_dim),\n",
    "            \"emitter\": { \"type\": \"area\", \"radiance\": { \"type\": \"rgb\", \"value\": [.4, .0, .1] } },\n",
    "        }\n",
    "\n",
    "    sail_colors = [\n",
    "        { \"type\": \"rgb\", \"value\": [0.8863, 0.2902, 0.2000] },\n",
    "        { \"type\": \"rgb\", \"value\": [0.4667, 0.4667, 0.4667] },\n",
    "        { \"type\": \"rgb\", \"value\": [0.9843, 0.7569, 0.3686] },\n",
    "        { \"type\": \"rgb\", \"value\": [0.5569, 0.7294, 0.2588] }\n",
    "    ]\n",
    "\n",
    "    assert sail_poses.shape[0] <= len(sail_colors)\n",
    "\n",
    "    for i, s in enumerate(sail_poses):\n",
    "        scene_dict_vis[f\"sail_{i}\"] = {\n",
    "            \"type\": \"ply\",\n",
    "            \"filename\": \"/home/daniel/Studium/masterarbeit/data/scenes/meshes/rectangle.ply\",\n",
    "            \"bsdf\": { \"type\": \"diffuse\", \"reflectance\": sail_colors[i] },\n",
    "            \"to_world\": tf.translate(s - box_dim).scale(sail_size).rotate([1., 0., 0.], angle=90.)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize and not out_view:\n",
    "    scene_dict_vis = utils.shoebox_scene_visual(resf=6, **config)\n",
    "\n",
    "    scene_dict_vis[\"integrator\"][\"max_depth\"] = 2\n",
    "\n",
    "    del scene_dict_vis[\"microphoneA\"]\n",
    "    scene_dict_vis[\"speaker\"][\"emitter\"][\"radiance\"][\"value\"] = 1e2\n",
    "\n",
    "    scene_dict_vis[\"sensor\"][\"film\"][\"width\"]  = 200 * 4\n",
    "    scene_dict_vis[\"sensor\"][\"film\"][\"height\"] = 200 * 3\n",
    "\n",
    "    scene_dict_vis[\"sensor\"][\"cameraA\"][\"to_world\"] = tf.look_at(\n",
    "        origin=(mic_poses[0] - box_dim),\n",
    "        target=(np.mean(sail_poses, axis=0) - box_dim),\n",
    "        up=[0, 0, 1],\n",
    "    )\n",
    "    scene_dict_vis[\"sensor\"][\"cameraA\"][\"fov\"] = 80\n",
    "\n",
    "    for i, s in enumerate(sail_poses):\n",
    "        scene_dict_vis[f\"sail_{i}\"] = scene_dict[f\"sail_{i}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    mi.set_variant(\"cuda_ad_rgb\")\n",
    "    scene  = mi.load_dict(scene_dict_vis)\n",
    "    params = mi.traverse(scene)\n",
    "    apply_transform(params, opt)\n",
    "    img = mi.render(scene, seed=sess_seed)\n",
    "    utils.plot_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and visualize:\n",
    "    # TODO rework\n",
    "    # exi = 19\n",
    "    V = np.load(f\"../data/ceiling-sail/ceiling-sail-single-mic.npy\")\n",
    "    G = np.load(f\"../data/ceiling-sail/ceiling-sail-single-mic_grads.npy\") * -1.\n",
    "    L = np.load(f\"../data/ceiling-sail/ceiling-sail-single-mic_losses.npy\")\n",
    "    assert V.shape[0] == L.shape[0]\n",
    "\n",
    "    L_min, L_max = np.min(L) * 0.99, np.max(L) * 1.01\n",
    "\n",
    "    for i in trange(240): #V.shape[0]):\n",
    "        opt[\"sail_0.vertex_positions\"] = mi.Point2f(V[i, 0])\n",
    "        opt[\"sail_1.vertex_positions\"] = mi.Point2f(V[i, 1])\n",
    "        opt[\"sail_2.vertex_positions\"] = mi.Point2f(V[i, 2])\n",
    "        opt[\"sail_3.vertex_positions\"] = mi.Point2f(V[i, 3])\n",
    "        apply_transform(params_vis)\n",
    "\n",
    "        img = mi.render(scene_vis, seed=sess_seed)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "        ax1.plot(L[:i+1])\n",
    "        ax1.scatter(i, L[i])\n",
    "        ax1.set_xlim(-5, L.shape[0] + 5)\n",
    "        ax1.set_ylim(L_min, L_max)\n",
    "        # ax1.set_yscale(\"log\")\n",
    "        ax1.set_xlabel(\"iteration\")\n",
    "        ax1.set_ylabel(\"loss\")\n",
    "\n",
    "        colors = ['C0', 'C3', 'C4', 'C5']\n",
    "        for j, c in enumerate(colors):\n",
    "            ax2.plot(V[:i+1, j, 0], V[:i+1, j, 1], c=c)\n",
    "        ax2.quiver(V[i, :, 0], V[i, :, 1], G[i, :, 0], G[i, :, 1], color=colors)\n",
    "\n",
    "        ticks = (np.linspace(-1., 1., 7), np.linspace(-30., 30., 7))\n",
    "        ax2.set_xticks(*ticks)\n",
    "        ax2.set_yticks(*ticks)\n",
    "        ax2.set_xlim(-1.1, 1.1)\n",
    "        ax2.set_ylim(-1.1, 1.1)\n",
    "        ax2.set_xlabel(\"$R_x$ in degrees\")\n",
    "        ax2.set_ylabel(\"$R_z$ in degrees\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.canvas.draw()\n",
    "        w, h = fig.canvas.get_width_height()\n",
    "        plot = np.frombuffer(fig.canvas.renderer.buffer_rgba(), dtype=np.uint8).reshape(h, w, 4)[:, :, :3]\n",
    "        plt.close()\n",
    "\n",
    "        img_conv = mi.TensorXf(bitmap(img, convert=True)).numpy().astype(np.uint8)\n",
    "        img_merg = np.vstack([img_conv, plot])\n",
    "        mi.util.write_bitmap(f\"../data/ceiling-sail/images/image_{i:03d}.png\", img_merg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Render Acoustic Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = mi.load_dict(scene_dict)\n",
    "params = mi.traverse(scene)\n",
    "apply_transform(params, opt)\n",
    "\n",
    "img = mi.render(scene, seed=sess_seed)\n",
    "utils.plot_hist(img[:, :, 0], **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare neutral to optimized position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for k in range(sail_poses.shape[0]):\n",
    "        opt[f\"sail_{k}.vertex_positions\"] = mi.Point2f(0., 0.)\n",
    "\n",
    "    apply_transform(params, opt)\n",
    "    img_ref = mi.render(scene, seed=sess_seed)\n",
    "\n",
    "    V = np.load(\"../data/ceiling-sail/ceiling-sail-single-mic.npy\")\n",
    "    for k in range(sail_poses.shape[0]):\n",
    "        opt[f\"sail_{k}.vertex_positions\"] = mi.Point2f(V[-1, k])\n",
    "\n",
    "    apply_transform(params, opt)\n",
    "    img = mi.render(scene, seed=sess_seed)\n",
    "\n",
    "    plot_hist(img[:, :, 0] - img_ref[:, :, 0], **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Gradient-Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_transform(params, opt)\n",
    "img = mi.render(scene, seed=sess_seed, seed_grad=sess_seed_g)\n",
    "\n",
    "dr.enable_grad(img)\n",
    "l = loss(img)\n",
    "dr.backward(l)\n",
    "g = mi.TensorXf(dr.grad(img))\n",
    "\n",
    "print(dr.min(g), dr.max(g))\n",
    "utils.plot_hist(g[:, :, 0], **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Optimization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "vals, losses, grads = [], [], []\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.set_title(\"losses\")\n",
    "ax1.set_xlim(-1, 51)\n",
    "\n",
    "ax2.set_title(\"values\")\n",
    "ax2.set_xlim(-1.1, 1.1)\n",
    "ax2.set_ylim(-1.1, 1.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 50\n",
    "if iters > 1:\n",
    "    n  = len(vals) + iters\n",
    "\n",
    "# for i in trange(iters) if iters > 1 else range(iters):\n",
    "for i in range(iters):\n",
    "    apply_transform(params, opt)\n",
    "    img = mi.render(scene, params, seed=sess_seed+i, seed_grad=sess_seed_g+i)\n",
    "\n",
    "    f = -1.\n",
    "    l = f * loss(img)\n",
    "    dr.backward(l, flags=dr.ADFlag.ClearNone if iters < 2 else dr.ADFlag.Default)\n",
    "\n",
    "    if iters < 2:\n",
    "        # key = \"sail_1.vertex_positions\"\n",
    "        # display(dr.unravel(mi.Point3f, dr.grad(params[key])))\n",
    "        display(dr.grad(opt[key]))\n",
    "    else:\n",
    "        angles, sail_grads = [], []\n",
    "        for key in sail_poses_dict:\n",
    "            angles.append(opt[key])\n",
    "            sail_grads.append(dr.grad(opt[key]))\n",
    "\n",
    "        vals.append(angles)\n",
    "        grads.append(sail_grads)\n",
    "        losses.append(l)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        V = np.array(vals)[:, :, 0]\n",
    "        G = np.array(grads)[:, :, 0]\n",
    "\n",
    "        ax1.clear()\n",
    "        ax1.set_title(\"losses\")\n",
    "        ax1.set_xlim(-n * 0.02, n * 1.02)\n",
    "\n",
    "        ax1.plot(np.array(losses)[:, 0])\n",
    "\n",
    "        ax2.clear()\n",
    "        ax2.set_title(\"values\")\n",
    "        ax2.plot(V[:, :, 0], V[:, :, 1])\n",
    "        ax2.set_xlim(-0.8, 0.8)\n",
    "        ax2.set_ylim(-0.8, 0.8)\n",
    "\n",
    "        ax2.quiver( V[-1, :, 0],  V[-1, :, 1],\n",
    "                   -G[-1, :, 0], -G[-1, :, 1])\n",
    "\n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if iters > 1:\n",
    "    V = np.stack([V, G])\n",
    "    for key in sail_poses_dict:\n",
    "        print(opt[key])\n",
    "\n",
    "    # np.save(\"../data/ceiling-sail/ceiling-sail-single-mic-02.npy\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss per optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # fname = \"../data/ceiling-sail/ceiling-sail-01.npy\"\n",
    "    # V = np.load(fname)\n",
    "    losses = []\n",
    "\n",
    "    for i in trange(V.shape[1]):\n",
    "        opt[\"sail_0.vertex_positions\"] = mi.Point2f(V[0, i, 0])\n",
    "        opt[\"sail_1.vertex_positions\"] = mi.Point2f(V[0, i, 1])\n",
    "        opt[\"sail_2.vertex_positions\"] = mi.Point2f(V[0, i, 2])\n",
    "        opt[\"sail_3.vertex_positions\"] = mi.Point2f(V[0, i, 3])\n",
    "        apply_transform(params, opt)\n",
    "\n",
    "        img = mi.render(scene, seed=sess_seed)\n",
    "        losses.append(loss(img))\n",
    "\n",
    "    # np.save(fname.replace('.npy', '_losses.npy'), np.array(losses))\n",
    "\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    ax.plot(np.array(losses)[:, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = False\n",
    "\n",
    "if heatmap:\n",
    "    k = 0\n",
    "    # opt[\"sail_0.vertex_positions\"] = mi.Point2f(-0.1, 0.7)\n",
    "    # opt[\"sail_1.vertex_positions\"] = mi.Point2f( 0.1, 0.7)\n",
    "    # opt[\"sail_2.vertex_positions\"] = mi.Point2f(V[0, -1, 2])\n",
    "    # opt[\"sail_3.vertex_positions\"] = mi.Point2f(V[0, -1, 3])\n",
    "\n",
    "    vA   = np.linspace(0.2, 0.35, 16, endpoint=True)\n",
    "    vB   = np.linspace(0.15, 0.30, 16, endpoint=True)\n",
    "    a, b = np.meshgrid(vA, vB)\n",
    "    data = np.zeros((3,) + a.shape)\n",
    "    print(vA)\n",
    "    print(vB)\n",
    "\n",
    "    for i in trange(a.shape[0]):\n",
    "        for j in range(a.shape[1]):\n",
    "            opt[f\"sail_{k}.vertex_positions\"] = mi.Point2f(a[i, j], b[i, j])\n",
    "            apply_transform(params, opt)\n",
    "\n",
    "            img = mi.render(scene, params, seed=sess_seed, seed_grad=sess_seed_g)\n",
    "            l   = loss(img)\n",
    "            dr.backward(l)\n",
    "            data[0, i, j] = l[0]\n",
    "            data[1, i, j] = dr.grad(opt[f\"sail_{k}.vertex_positions\"]).x[0]\n",
    "            data[2, i, j] = dr.grad(opt[f\"sail_{k}.vertex_positions\"]).y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if heatmap:\n",
    "    n = 2\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "\n",
    "    contf = ax.contourf(a, b, data[0], cmap=\"inferno\")\n",
    "    # ax.contour(a, b, data[0], colors='k', alpha=0.75, linewidths=0.3)\n",
    "\n",
    "    ax.quiver(a, b, data[1], data[2], color='C1')\n",
    "\n",
    "    fig.colorbar(contf, ax=ax, fraction=0.1, shrink=0.8).set_label('loss')\n",
    "    # ax.set_xticks(vA[::n], np.round(vA * 30., 1)[::n])\n",
    "    # ax.set_yticks(vB[::n], np.round(vB * 30., 1)[::n])\n",
    "    ax.set_xlabel(\"$R_x$\")\n",
    "    ax.set_ylabel(\"$R_z$\")\n",
    "    ax.set_title(f\"Loss Heatmap - ceiling sail {k}\")\n",
    "\n",
    "    # fig.savefig(f\"../data/ceiling-sail/ceiling-sail-single-mic-heatmap-sail_{k}.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average distance/time emitter-sail-receiver reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_pos       = np.array(config[\"speaker_pos\"])\n",
    "em_dist      = np.linalg.norm(sail_poses - em_pos,       axis=1)\n",
    "mic1_dist    = np.linalg.norm(sail_poses - mic_poses[0], axis=1) + em_dist\n",
    "em_mic1_dist = np.linalg.norm(em_pos     - mic_poses[0], axis=0)\n",
    "\n",
    "print(mic1_dist    / 343)\n",
    "print(em_mic1_dist / 343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "07ec54878c3c410ca11e8b72444a00e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0c35e343c7ef48baa2f16a89425e45c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "121009d8ad1a400bb0faff5650af82b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "148400d8a7d44374a39589fb0c0d7d46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "1bf5946071df47e686b46976c829f4d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2262fd9b5af64b308ea9fd1d5b0b0494": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0c35e343c7ef48baa2f16a89425e45c9",
       "max": 1,
       "style": "IPY_MODEL_64638caeb3de4839809e4dae0dc2b071",
       "value": 1
      }
     },
     "328d9c2dbd124dc19ae91ce0cb551403": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_493c51e117d545a799ea5a57b9bfb258",
        "IPY_MODEL_bc89b3250375423e82db58560d690de3"
       ],
       "layout": "IPY_MODEL_4352d146b8ac4b478de6fb1778cd5d41"
      }
     },
     "384ad0e5d7934e3b89951358a9d19186": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cfb38214efa947568144d4522d548de6",
        "IPY_MODEL_c689f166d13242938ff57a24b0817d41"
       ],
       "layout": "IPY_MODEL_121009d8ad1a400bb0faff5650af82b3"
      }
     },
     "4352d146b8ac4b478de6fb1778cd5d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "493c51e117d545a799ea5a57b9bfb258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a3f5661d51064b2eb0e9ef5d1b0bb8aa",
       "style": "IPY_MODEL_b6610365565e4df1ab9f0dacfc0ee04a",
       "value": "Rendering (13.9s, ETA: 0ms)"
      }
     },
     "5ca4d20425df44658fb252c281f019fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "5ead71d75c28401eb61aaec2db79be71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1bf5946071df47e686b46976c829f4d0",
       "style": "IPY_MODEL_f87d0eda3bba45a6b5101e92ec75ab51",
       "value": "Rendering (13.9s, ETA: 0ms)"
      }
     },
     "64638caeb3de4839809e4dae0dc2b071": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "64e097a514c04437bf30f0d12463d973": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_5ca4d20425df44658fb252c281f019fd",
       "max": 1,
       "style": "IPY_MODEL_07ec54878c3c410ca11e8b72444a00e8",
       "value": 1
      }
     },
     "6c57fb913d8b47c7ad6a2129294b7f4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c93f1917313f474c96018ef6f4db65b3",
        "IPY_MODEL_e1ec3d6d53ce43e386de054ab61583b5"
       ],
       "layout": "IPY_MODEL_cdad0127f4f6443a8643eec4140c2b50"
      }
     },
     "76ef1ebaa1c34d4ca27c8fda94d21eae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7995615f2c5648de87bc7080ce7043aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7b6bc4d7291243dcb4838f1745959151": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "895ccf032eb44c24a5e60315ff3eba16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "9b86f1cff37c4fdc9e619cd95a70a256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a3f5661d51064b2eb0e9ef5d1b0bb8aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a40669281c224b5f85fa4485491c3950": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d7bb96993f3a4db4bb2aa71270257a1b",
        "IPY_MODEL_64e097a514c04437bf30f0d12463d973"
       ],
       "layout": "IPY_MODEL_76ef1ebaa1c34d4ca27c8fda94d21eae"
      }
     },
     "a6576f2dd3604fb79879caa19911b935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b6610365565e4df1ab9f0dacfc0ee04a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b91e3ad4740c42798db154827fbe5477": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bc89b3250375423e82db58560d690de3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_148400d8a7d44374a39589fb0c0d7d46",
       "max": 1,
       "style": "IPY_MODEL_e4fb04aa19fd44a49f0fdd5e9a4fa9fd",
       "value": 1
      }
     },
     "c689f166d13242938ff57a24b0817d41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f1cc99986b0b46b58cae7fd82c5aad84",
       "max": 1,
       "style": "IPY_MODEL_e609a9ba6dff485bbde84e1fe599b2ba",
       "value": 1
      }
     },
     "c93f1917313f474c96018ef6f4db65b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ea57520c73bb4bf49de6ef0ab85b5fd5",
       "style": "IPY_MODEL_9b86f1cff37c4fdc9e619cd95a70a256",
       "value": "Rendering (34.1s, ETA: 0ms)"
      }
     },
     "cdad0127f4f6443a8643eec4140c2b50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cfb38214efa947568144d4522d548de6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f92a16e114714e9e82f1e60a0980cb2d",
       "style": "IPY_MODEL_e11cbf07e2d240348cdc470bd4f234e7",
       "value": "Rendering (13.8s, ETA: 0ms)"
      }
     },
     "d7bb96993f3a4db4bb2aa71270257a1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7995615f2c5648de87bc7080ce7043aa",
       "style": "IPY_MODEL_b91e3ad4740c42798db154827fbe5477",
       "value": "Rendering (14s, ETA: 0ms)"
      }
     },
     "d827ae3e316a4961b44fc24c2ef633a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5ead71d75c28401eb61aaec2db79be71",
        "IPY_MODEL_2262fd9b5af64b308ea9fd1d5b0b0494"
       ],
       "layout": "IPY_MODEL_7b6bc4d7291243dcb4838f1745959151"
      }
     },
     "e11cbf07e2d240348cdc470bd4f234e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e1ec3d6d53ce43e386de054ab61583b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_895ccf032eb44c24a5e60315ff3eba16",
       "max": 1,
       "style": "IPY_MODEL_a6576f2dd3604fb79879caa19911b935",
       "value": 1
      }
     },
     "e4fb04aa19fd44a49f0fdd5e9a4fa9fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e609a9ba6dff485bbde84e1fe599b2ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ea57520c73bb4bf49de6ef0ab85b5fd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f1cc99986b0b46b58cae7fd82c5aad84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "100%"
      }
     },
     "f87d0eda3bba45a6b5101e92ec75ab51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f92a16e114714e9e82f1e60a0980cb2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
